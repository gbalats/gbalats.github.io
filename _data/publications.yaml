- doi: "10.1561/2500000014"
  url: http://dx.doi.org/10.1561/2500000014
  title: >
    Pointer Analysis
  authors:
    - Yannis Smaragdakis
    - George Balatsouras
  journal: "Foundations and Trends&#174; in Programming Languages"
  pdf_link: http://yanniss.github.io/points-to-tutorial15.pdf
  abstract: |
    Pointer analysis is a fundamental static program analysis, with a
    rich literature and wide applications. The goal of pointer
    analysis is to compute an approximation of the set of program
    objects that a pointer variable or expression can refer to. We
    present an introduction and survey of pointer analysis techniques,
    with an emphasis on distilling the essence of common analysis
    algorithms. To this end, we focus on a declarative presentation of
    a common core of pointer analyses: algorithms are modeled as
    configurable, yet easy-to-follow, logical specifications. The
    specifications serve as a starting point for a broader discussion
    of the literature, as independent threads spun from the
    declarative model.

- doi: "2509136.2509530"
  title: >
    Class Hierarchy Complementation: Soundly Completing a Partial Type Graph
  authors:
    - George Balatsouras
    - Yannis Smaragdakis
  conference: "OOPSLA '13"
  pdf_link: http://yanniss.github.io/jphantom-oopsla13.pdf
  pps_link: /assets/presentations/oopsla2013-jphantom.pdf
  abstract: |
    We present the problem of class hierarchy complementation: given a
    partially known hierarchy of classes together with subtyping
    constraints (“A has to be a transitive subtype of B”) complete the
    hierarchy so that it satisfies all constraints. The problem has
    immediate practical application to the analysis of partial
    programs—e.g., it arises in the process of providing a sound
    handling of “phantom classes” in the Soot program analysis
    framework. We provide algorithms to solve the hierarchy
    complementation problem in the single inheritance and multiple
    inheritance settings. We also show that the problem in a language
    such as Java, with single inheritance but multiple subtyping and
    distinguished class vs. interface types, can be decomposed into
    separate single- and multiple-subtyping instances. We implement
    our algorithms in a tool, JPhantom, which complements partial Java
    bytecode programs so that the result is guaranteed to satisfy the
    Java verifier requirements. JPhantom is highly scalable and runs
    in mere seconds even for large input applications and complex
    constraints (with a maximum of 14s for a 19MB binary).

- doi: "2509136.2509524"
  title: >
    Set-Based Pre-Processing for Points-To Analysis
  authors:
    - Yannis Smaragdakis
    - George Balatsouras
    - George Kastrinis
  conference: "OOPSLA '13"
  pdf_link: http://yanniss.github.io/set-based-oopsla13.pdf
  abstract: |
    We present set-based pre-analysis: a virtually universal
    optimization technique for flow-insensitive points-to
    analysis. Points-to analysis computes a static abstraction of how
    object values flow through a program’s variables. Set-based
    pre-analysis relies on the observation that much of this reasoning
    can take place at the set level rather than the value
    level. Computing constraints at the set level results in
    significant optimization opportunities: we can rewrite the in- put
    program into a simplified form with the same essential points-to
    properties. This rewrite results in removing both local variables
    and instructions, thus simplifying the subsequent value-based
    points-to computation. Effectively, set-based pre-analysis puts
    the program in a normal form optimized for points-to analysis.
    Compared to other techniques for off-line optimization of
    points-to analyses in the literature, the new elements of our
    approach are the ability to eliminate statements, and not just
    variables, as well as its modularity: set-based pre-analysis can
    be performed on the input just once, e.g., allowing the
    pre-optimization of libraries that are subsequently reused many
    times and for different analyses. In experiments with Java
    programs, set-based pre-analysis eliminates 30% of the program’s
    local variables and 30% or more of computed context-sensitive
    points-to facts, over a wide set of benchmarks and analyses,
    resulting in a 24% average speedup (max: 103%, median: 20%).

- doi: "594291.2594320"
  title: >
    Introspective Analysis: Context-Sensitivity, Across the Board
  authors:
    - Yannis Smaragdakis
    - George Kastrinis
    - George Balatsouras
  conference: "PLDI '14"
  pdf_link: https://zenodo.org/record/12713/files/main.pdf
  abstract: |
    Context-sensitivity is the primary approach for adding more
    precision to a points-to analysis, while hopefully also
    maintaining scalability. An oft-reported problem with
    context-sensitive analyses, however, is that they are bi-modal:
    either the analysis is precise enough that it manipulates only
    manageable sets of data, and thus scales impressively well, or the
    analysis gets quickly derailed at the first sign of imprecision
    and becomes orders-of-magnitude more expensive than would be
    expected given the program’s size. There is currently no approach
    that makes precise context-sensitive analyses (of any flavor:
    call-site-, object-, or type-sensitive) scale across the board at
    a level comparable to that of a context-insensitive analysis. To
    address this issue, we propose introspective analysis: a technique
    for uniformly scaling context-sensitive analysis by eliminating
    its performance-detrimental behavior, at a small precision
    expense. Introspective analysis consists of a common adaptivity
    pattern: first perform a context-insensitive analysis, then use
    the results to selectively refine (i.e., analyze
    context-sensitively) program elements that will not cause
    explosion in the running time or space. The technical challenge is
    to appropriately identify such program elements. We show that a
    simple but principled approach can be remarkably effective,
    achieving scalability (often with dramatic speedup) for benchmarks
    previously completely out-of-reach for deep context-sensitive
    analyses.
